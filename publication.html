<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <title> Hao DONG | Publications </title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <link href="css/common.css" type="text/css" rel="stylesheet" />
    <link href="css/research.css" type="text/css" rel="stylesheet" />
    <link href="css/jcarousel.css" type="text/css" rel="stylesheet" />
    <a href = "https://github.com/Holdlen2DH">
        <img class = "fork-me" style = "position:absolute; top:0;right:0;border:0" 
            src = "./Holdlen2DH_files/forkme.png", alt = "Fork me on Github">
    </a>
    <script type="text/javascript" src="javascript/jquery_1.3.2.js"></script>
    <script type="text/javascript" src="javascript/jcarousel.js"></script>
    <script type="text/javascript">
    jQuery(document).ready(function () {
        jQuery('#jcarouselMetro').jcarousel({
            scroll: 1,
            wrap: 'both'
        });
        jQuery('#jcarouselInvites').jcarousel({
            scroll: 1,
            wrap: 'both'
        });
    });
    </script>
</head>
<body>
    <!-- Begin container -->
    <div id="container">
        <!-- Begin navigation container -->
        <div class="navigationContainer">
            <!-- Begin logo -->
            <div class="logo"> 
                <a href="index.html">
                    <img src="Holdlen2DH_files/logo.png" alt="" width=150px/>
                </a> 
            </div>
            <!--/ End logo -->
            <!-- Begin navigation -->
            <div class="navigation">
                <ul>
                    <li><a href="index.html">Home</a></li>
                    <li><a href="HaoDONG_CV.pdf">Curriculum Vitae</a></li>
                    <li class="active"><a href="publication.html">Publication</a></li>
                    <li><a href="fun_proj.html">Fun Projects</a></li>
                    <li><a href="blog.html">Blog</a></li>
                </ul>
            </div>
            <!--/ End navigation -->
        </div>
        <!--/ End navigation container -->
        <!-- Begin grey separator -->
        <div class="greySeparator"></div>
        <!--/ End grey separator -->
        <!-- Begin portfolio content -->
        <div class="portfolioContent">
            <!-- Begin description -->
            <div class="description">
                <div class="pub_title">Copula-Based Joint Statistical Model for Polarimetric Features and 
                    Its Application in PolSAR Image Classification
                    <a href="http://ieeexplore.ieee.org/document/7970131/">[PDF]</a>
                </div>
                <h2>
                    <b>Hao Dong</b>, Xin Xu, Haigang Sui, Feng Xu, and Junyi Liu.
                    <div class="pub_press">IEEE Transactions on Geoscience and Remote Sensing, 2017.</div> 
                </h2>
                <p>
                    Polarimetric features are essential to polarimetric synthetic aperture radar (PolSAR) image classification 
                    for their better physical understanding of terrain targets. The designed classifiers often achieve better 
                    performance via feature combination. However, the simply combination of polarimetric features cannot fully 
                    represent the information in PolSAR data, and the statistics of polarimetric features are not extensively studied. 
                    In this paper, we propose a joint statistical model for polarimetric features derived from the covariance matrix.
                    The model is based on copula for multivariate distribution modeling and alpha-stable distribution for 
                    marginal probability density function estimations. We denote such model by CoAS. 
                    The proposed model has several advantages. First, the model is designed for real-valued polarimetric features, 
                    which avoids the complex matrix operations associated with the covariance and coherency matrices. 
                    Second, these features consist of amplitudes, correlation magnitudes, 
                    and phase differences between polarization channels. They efficiently encode information in PolSAR data, 
                    which lends itself to interpretability of results in the PolSAR context. 
                    Third, the CoAS model takes advantage of both copula and the alpha-stable distribution, 
                    which makes it general and flexible to construct the joint statistical model accounting for dependence between 
                    features. Finally, a supervised Markovian classification scheme based on the proposed CoAS model is presented. 
                    The classification results on several PolSAR data sets validate the efficacy of CoAS in PolSAR image modeling and 
                    classification. The proposed CoAS-based classifiers yield superior performance, especially in building areas. 
                    The overall accuracies are higher by 5%-10%, compared with other benchmark statistical model-based classification techniques. 
                </p>
            </div>
            <!--/ End description -->
            <!-- Begin image -->
            <div class="image">
                <img src="publication/COAS/fig_csfn_flowchart.jpg" alt="" width="280"/>
            </div>
            <div class="image">
                <img src="publication/COAS/fig_rs2_csfn_result.png" alt="" width="280"/>
            </div>
            <!--/ End image -->
            <!-- Clear -->
            <div class="clear"></div>
            
            <!-- Begin grey separator -->
            <div class="greySeparator"></div>

            <!-- Begin description -->
            <div class="description">
                <div class="pub_title">Individual Building Extraction from TerraSAR-X Images Based on Ontological Semantic Analysis
                    <a href="http://www.mdpi.com/2072-4292/8/9/708">[PDF]</a>
                </div>
                <h2>
                    Rong Gui, Xin Xu, <b>Hao Dong</b>, and Fangling Pu.
                    <div class="pub_press">Remote Sensing, 8(9), 708, 2016.
                    </div> 
                </h2>
                <p>Accurate building information plays a crucial role for urban planning, human settlements 
                    and environmental management. Synthetic aperture radar (SAR) images, which deliver images
                     with metric resolution, allow for analyzing and extracting detailed information on urban areas. 
                     In this paper, we consider the problem of extracting individual buildings from SAR images 
                     based on domain ontology. By analyzing a building scattering model with different orientations 
                     and structures, the building ontology model is set up to express multiple characteristics of
                     individual buildings. Under this semantic expression framework, 
                     an object-based SAR image segmentation method is adopted to provide homogeneous image objects,
                     and three categories of image object features are extracted. 
                     Semantic rules are implemented by organizing image object features, 
                     and the individual building objects expression based on an ontological 
                     semantic description is formed. Finally, the building primitives are used 
                     to detect buildings among the available image objects. Experiments on TerraSAR-X images of 
                     Foshan city, China, with a spatial resolution of 1.25 m × 1.25 m, 
                     have shown the total extraction rates are above 84%. 
                     The results indicate the ontological semantic method can exactly extract flat-roof 
                     and gable-roof buildings larger than 250 pixels with different orientations 
                </p>
            </div>
            <!--/ End description -->
            <!-- Begin image -->
            <div class="image">
                <img src="publication/OntoSema_IB_Exts/fig_data3_results.png" alt="" width="280"/>
            </div>
            <!--/ End image -->
            <!-- Clear -->
            <div class="clear"></div>
            
            <!-- Begin grey separator -->
            <div class="greySeparator"></div>

            <!-- Begin description -->
            <div class="description">
                <div class="pub_title">Metric learning based collapsed building extraction from post-earthquake PolSAR imagery 
                    <a href="http://ieeexplore.ieee.org/document/7730237/">[PDF]</a>
                    <a href="publication/ITML_CB_EXTS/igarss2016_dh_poster.pdf">[Poster]</a>
                </div>
                <h2>
                    <b>Hao Dong</b>, Xin Xu, Rong Gui, Chao Song, and Haigang Sui.
                    <div class="pub_press">Geoscience and Remote Sensing Symposium(IGARSS), IEEE 2016 International, 
                        2016, Beijing, China, 4742-4745, 2016.
                    </div> 
                </h2>
                <p>In this paper we proposed a metric learning-based method to 
                    extract collapsed buildings from post-earthquake PolSAR imagery.
                    In this method, eight building and orientation related
                    features, including entropy H, the average scattering angle α,
                    anisotropy A, the circular polarization correlation coefficient
                    ρ and the four scattering powers of Yamaguchi 4 component
                    decomposition with a rotation of the coherency matrix,
                    are considered and analyzed. Then a transformation matrix is
                    learned from collapsed and intact building samples via an improved
                    informational-theoretic metric learning(ITML). With
                    such a transformation matrix, the features are projected into
                    a low-dimension space to mitigate the impact of topography
                    and building’s aspect angle. Finally a k−NN classifier is utilized
                    to distinguish collapsed and intact buildings. The proposed
                    method is tested on one RadarSAT-2 PolSAR image acquired
                    after 2010 Yushu Earthquake in the Qinghai Province
                    of China. Results are validated by the manually interpretation
                    map of a very high resolution (VHR) optical image. It shows
                    that, the method is efficient to extract collapsed building areas
                    using limited samples and only one post-earthquake PolSAR image. 
                </p>
            </div>
            <!--/ End description -->
            <!-- Begin image -->
            <div class="image">
                <img src="publication/ITML_CB_EXTS/fig_y4r_rgb_sams.jpg" alt="" width="250"/>
            </div>
             <div class="image">
                <img src="publication/ITML_CB_EXTS/fig_cbexts_rslt.jpg" alt="" width="250"/>
            </div>
            <!--/ End image -->
            <!-- Clear -->
            <div class="clear"></div>
            
            <!-- Begin grey separator -->
            <div class="greySeparator"></div>

        </div>
        <!--/ End portfolio content -->
        
        <!-- Begin footer -->
        <div class="footer"> Copyright &copy; 2017, <a href="index.html">Hao DONG</a>. All Rights Reserved. </a>
        </div>
        <!--/ End footer -->
    </div>
    <!--/ End container -->
</body>
</html>
